{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки и присваиваем им сокращенные названия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv('kr2_var2.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем файл с данными используя библиотеку пандас."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>52.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.93</td>\n",
       "      <td>3.23</td>\n",
       "      <td>106.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>70.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.17</td>\n",
       "      <td>4.80</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>74.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>8.84</td>\n",
       "      <td>5.20</td>\n",
       "      <td>86.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>79.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.74</td>\n",
       "      <td>80.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>74.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>9.15</td>\n",
       "      <td>4.32</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>62</td>\n",
       "      <td>f</td>\n",
       "      <td>416.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.57</td>\n",
       "      <td>6.30</td>\n",
       "      <td>55.7</td>\n",
       "      <td>650.9</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>102.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3.02</td>\n",
       "      <td>63.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>71.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>87.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.63</td>\n",
       "      <td>66.7</td>\n",
       "      <td>64.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>46</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.20</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>59</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.07</td>\n",
       "      <td>5.30</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex    ALP    ALT    CHE  CHOL   CREA    GGT  PROT  Category\n",
       "0     32   m   52.5    7.7   6.93  3.23  106.0   12.1  69.0         0\n",
       "1     32   m   70.3   18.0  11.17  4.80   74.0   15.6  76.5         0\n",
       "2     32   m   74.7   36.2   8.84  5.20   86.0   33.2  79.3         0\n",
       "3     32   m   52.0   30.6   7.33  4.74   80.0   33.8  75.7         0\n",
       "4     32   m   74.1   32.6   9.15  4.32   76.0   29.9  68.7         0\n",
       "..   ...  ..    ...    ...    ...   ...    ...    ...   ...       ...\n",
       "610   62   f  416.6    5.9   5.57  6.30   55.7  650.9  68.5         1\n",
       "611   64   f  102.8    2.9   1.54  3.02   63.0   35.9  71.3         1\n",
       "612   64   f   87.3    3.5   1.66  3.63   66.7   64.2  82.0         1\n",
       "613   46   f    NaN   39.0   3.56  4.20   52.0   50.0  71.0         1\n",
       "614   59   f    NaN  100.0   9.07  5.30   67.0   34.0  68.0         1\n",
       "\n",
       "[615 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводим датасет на экран. Количество наблюдений 615, количество факторов из них 8 количественных и 1 качественный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALP</th>\n",
       "      <td>18</td>\n",
       "      <td>0.029268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHOL</th>\n",
       "      <td>10</td>\n",
       "      <td>0.016260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROT</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALT</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREA</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total   Percent\n",
       "ALP          18  0.029268\n",
       "CHOL         10  0.016260\n",
       "PROT          1  0.001626\n",
       "ALT           1  0.001626\n",
       "Category      0  0.000000\n",
       "GGT           0  0.000000\n",
       "CREA          0  0.000000\n",
       "CHE           0  0.000000\n",
       "Sex           0  0.000000\n",
       "Age           0  0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking Missing data\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем наличие пропусков, присутствуют они только в числовых значениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Missing data (numeric)\n",
    "def fill_missing_num(x):\n",
    "    num_var = list(x._get_numeric_data().columns)\n",
    "    for col_names in num_var:        \n",
    "        prep_med = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        prep_med.fit(x[num_var])\n",
    "        x[num_var] = prep_med.transform(x[num_var])\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавляемся от пропусков, используя стратегию заполнения их средними значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NA \n",
    "from sklearn.impute import SimpleImputer\n",
    "df = fill_missing_num(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREA</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHOL</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALP</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total  Percent\n",
       "Category      0      0.0\n",
       "PROT          0      0.0\n",
       "GGT           0      0.0\n",
       "CREA          0      0.0\n",
       "CHOL          0      0.0\n",
       "CHE           0      0.0\n",
       "ALT           0      0.0\n",
       "ALP           0      0.0\n",
       "Sex           0      0.0\n",
       "Age           0      0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking Missing data\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем конечную проверку на наличие пропусков и убеждаемся, что их нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Encoding\n",
    "def encoding_char(x):\n",
    "    char_var = list(set(x.columns) - set(x._get_numeric_data().columns))\n",
    "    for col_names in char_var:\n",
    "        f = pd.factorize(x[col_names])\n",
    "        x[col_names] = pd.factorize(x[col_names])[0]\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодируем качественные переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "df = encoding_char(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные результаты запишем в исходный датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.50000</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.93</td>\n",
       "      <td>3.23</td>\n",
       "      <td>106.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.30000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.17</td>\n",
       "      <td>4.80</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.70000</td>\n",
       "      <td>36.2</td>\n",
       "      <td>8.84</td>\n",
       "      <td>5.20</td>\n",
       "      <td>86.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>79.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00000</td>\n",
       "      <td>30.6</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.74</td>\n",
       "      <td>80.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.10000</td>\n",
       "      <td>32.6</td>\n",
       "      <td>9.15</td>\n",
       "      <td>4.32</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>416.60000</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.57</td>\n",
       "      <td>6.30</td>\n",
       "      <td>55.7</td>\n",
       "      <td>650.9</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>102.80000</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3.02</td>\n",
       "      <td>63.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>71.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>87.30000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.63</td>\n",
       "      <td>66.7</td>\n",
       "      <td>64.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.28392</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.20</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.28392</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.07</td>\n",
       "      <td>5.30</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Sex        ALP    ALT    CHE  CHOL   CREA    GGT  PROT  Category\n",
       "0    32.0    0   52.50000    7.7   6.93  3.23  106.0   12.1  69.0       0.0\n",
       "1    32.0    0   70.30000   18.0  11.17  4.80   74.0   15.6  76.5       0.0\n",
       "2    32.0    0   74.70000   36.2   8.84  5.20   86.0   33.2  79.3       0.0\n",
       "3    32.0    0   52.00000   30.6   7.33  4.74   80.0   33.8  75.7       0.0\n",
       "4    32.0    0   74.10000   32.6   9.15  4.32   76.0   29.9  68.7       0.0\n",
       "..    ...  ...        ...    ...    ...   ...    ...    ...   ...       ...\n",
       "610  62.0    1  416.60000    5.9   5.57  6.30   55.7  650.9  68.5       1.0\n",
       "611  64.0    1  102.80000    2.9   1.54  3.02   63.0   35.9  71.3       1.0\n",
       "612  64.0    1   87.30000    3.5   1.66  3.63   66.7   64.2  82.0       1.0\n",
       "613  46.0    1   68.28392   39.0   3.56  4.20   52.0   50.0  71.0       1.0\n",
       "614  59.0    1   68.28392  100.0   9.07  5.30   67.0   34.0  68.0       1.0\n",
       "\n",
       "[615 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как выглядит таблица после кодирования, можем видеть, что теперь все переменные являются числовыми и с ними можно работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наш датасет на обучающую и тестовую выборки в пропорции 20% / 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler().fit(X_train)\n",
    "X_train = sc_X.transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем шкалирование данных с помощью библиотеки sklearn.preprocessing, также стоит обратить внимание, что наша эндогенная переменная в шкалировании не нуждается, она уже должна быть дискретного типа (0;1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.514381\n",
      "         Iterations 7\n",
      "                        Results: Logit\n",
      "===============================================================\n",
      "Model:              Logit            Pseudo R-squared: -0.293  \n",
      "Dependent Variable: y                AIC:              524.1512\n",
      "Date:               2020-12-29 10:46 BIC:              561.9375\n",
      "No. Observations:   492              Log-Likelihood:   -253.08 \n",
      "Df Model:           8                LL-Null:          -195.80 \n",
      "Df Residuals:       483              LLR p-value:      1.0000  \n",
      "Converged:          1.0000           Scale:            1.0000  \n",
      "No. Iterations:     7.0000                                     \n",
      "-----------------------------------------------------------------\n",
      "         Coef.    Std.Err.      z      P>|z|     [0.025    0.975]\n",
      "-----------------------------------------------------------------\n",
      "x1       0.1267     0.1154    1.0979   0.2722   -0.0995    0.3528\n",
      "x2       0.1144     0.1188    0.9625   0.3358   -0.1185    0.3472\n",
      "x3      -0.3371     0.1626   -2.0725   0.0382   -0.6559   -0.0183\n",
      "x4      -0.0696     0.1628   -0.4272   0.6692   -0.3887    0.2496\n",
      "x5      -0.1815     0.1401   -1.2958   0.1950   -0.4561    0.0930\n",
      "x6      -0.6025     0.1388   -4.3411   0.0000   -0.8745   -0.3305\n",
      "x7      -0.0889     0.1609   -0.5525   0.5806   -0.4042    0.2264\n",
      "x8       2.9916     0.3304    9.0547   0.0000    2.3440    3.6392\n",
      "x9       0.1221     0.1260    0.9692   0.3324   -0.1248    0.3691\n",
      "===============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "import statsmodels.api as sm\n",
    "lr = sm.Logit(y_train, X_train).fit()\n",
    "print(lr.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим базовую модель и посмотрим отчет по этой модели. Можем видеть, что 3 переменные значимые, p-value по остальным переменным превышает 3,82% и я не буду использовать их для построения классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value < 3,82 % Features\n",
    "X_train = X_train[:,[2, 5, 7]]\n",
    "X_test = X_test[:,[2, 5, 7, ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем тестовую и обучающие выборки, оставив в них только значимые переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set (2 variables)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 13).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349593495934959"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = lr.predict(X_test)\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем качество модели, видим что уровень качества очень высокий, то есть больше 93% объектов распознаны верно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106   2]\n",
      " [  6   9]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим таблицу сопряженности, видим, что 6 положительных случаев ложно определены как отрицательные, в тоже время 2 негативных исхода, определены моделью, как позитивные. 115 объектов модель распознала верно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "obj = {'X_train': X_train, 'X_test': X_test,'y_train': y_train,'y_test': y_test}\n",
    "output = open('data.pkl', 'wb')\n",
    "pickle.dump(obj, output, 2)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем и поместим в файл data.pkl наши тестовую и обучающую выборки, для дальнейщего использования при построении остальных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "input = open('data.pkl', 'rb')\n",
    "obj = pickle.load(input)\n",
    "input.close()\n",
    "X_train = obj[\"X_train\"]\n",
    "X_test = obj[\"X_test\"]\n",
    "y_train = obj[\"y_train\"]\n",
    "y_test = obj[\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем наши данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки и что важно обновляем их через командую строку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "cnn = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn.add(Dense(units = 3,  activation = 'relu', input_dim = 3))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим нейронную сеть прямой передачи сигнала. Так как параметров для классификации было выбрано 5, соответственно на входном слое находится 5 нейронов. На втором слое выберем 1 нейрон."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.7846 - val_loss: 0.5058 - val_accuracy: 0.8699\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 999us/step - loss: 0.5295 - accuracy: 0.8496 - val_loss: 0.4612 - val_accuracy: 0.8537\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 971us/step - loss: 0.4867 - accuracy: 0.8760 - val_loss: 0.4201 - val_accuracy: 0.8862\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 869us/step - loss: 0.4469 - accuracy: 0.8862 - val_loss: 0.3884 - val_accuracy: 0.8943\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 788us/step - loss: 0.4125 - accuracy: 0.8821 - val_loss: 0.3591 - val_accuracy: 0.8943\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 901us/step - loss: 0.3835 - accuracy: 0.8862 - val_loss: 0.3365 - val_accuracy: 0.9024\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 869us/step - loss: 0.3590 - accuracy: 0.8882 - val_loss: 0.3178 - val_accuracy: 0.9024\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 949us/step - loss: 0.3380 - accuracy: 0.8902 - val_loss: 0.3021 - val_accuracy: 0.9024\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 877us/step - loss: 0.3210 - accuracy: 0.8882 - val_loss: 0.2898 - val_accuracy: 0.9024\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 803us/step - loss: 0.3061 - accuracy: 0.8882 - val_loss: 0.2786 - val_accuracy: 0.9024\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 790us/step - loss: 0.2941 - accuracy: 0.8882 - val_loss: 0.2705 - val_accuracy: 0.9024\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 878us/step - loss: 0.2839 - accuracy: 0.8882 - val_loss: 0.2638 - val_accuracy: 0.9024\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 922us/step - loss: 0.2748 - accuracy: 0.8882 - val_loss: 0.2579 - val_accuracy: 0.9024\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 870us/step - loss: 0.2674 - accuracy: 0.8882 - val_loss: 0.2535 - val_accuracy: 0.9024\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 990us/step - loss: 0.2609 - accuracy: 0.8862 - val_loss: 0.2493 - val_accuracy: 0.9024\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 860us/step - loss: 0.2555 - accuracy: 0.8862 - val_loss: 0.2462 - val_accuracy: 0.9024\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 921us/step - loss: 0.2507 - accuracy: 0.8862 - val_loss: 0.2438 - val_accuracy: 0.9024\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 853us/step - loss: 0.2463 - accuracy: 0.8923 - val_loss: 0.2412 - val_accuracy: 0.9024\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 879us/step - loss: 0.2423 - accuracy: 0.8943 - val_loss: 0.2386 - val_accuracy: 0.9024\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 798us/step - loss: 0.2388 - accuracy: 0.8984 - val_loss: 0.2367 - val_accuracy: 0.9024\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 834us/step - loss: 0.2358 - accuracy: 0.9004 - val_loss: 0.2349 - val_accuracy: 0.9024\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9024 - val_loss: 0.2331 - val_accuracy: 0.9024\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 885us/step - loss: 0.2306 - accuracy: 0.9024 - val_loss: 0.2317 - val_accuracy: 0.9024\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 930us/step - loss: 0.2281 - accuracy: 0.9024 - val_loss: 0.2305 - val_accuracy: 0.9024\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 885us/step - loss: 0.2259 - accuracy: 0.9024 - val_loss: 0.2291 - val_accuracy: 0.9024\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 937us/step - loss: 0.2240 - accuracy: 0.9024 - val_loss: 0.2276 - val_accuracy: 0.9024\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 901us/step - loss: 0.2224 - accuracy: 0.9024 - val_loss: 0.2266 - val_accuracy: 0.9024\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 902us/step - loss: 0.2206 - accuracy: 0.9024 - val_loss: 0.2256 - val_accuracy: 0.9024\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 965us/step - loss: 0.2189 - accuracy: 0.9065 - val_loss: 0.2246 - val_accuracy: 0.9024\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 891us/step - loss: 0.2171 - accuracy: 0.9045 - val_loss: 0.2233 - val_accuracy: 0.9106\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 950us/step - loss: 0.2155 - accuracy: 0.9085 - val_loss: 0.2219 - val_accuracy: 0.9187\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 899us/step - loss: 0.2137 - accuracy: 0.9126 - val_loss: 0.2211 - val_accuracy: 0.9187\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 917us/step - loss: 0.2122 - accuracy: 0.9167 - val_loss: 0.2202 - val_accuracy: 0.9187\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 978us/step - loss: 0.2106 - accuracy: 0.9167 - val_loss: 0.2193 - val_accuracy: 0.9268\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 877us/step - loss: 0.2090 - accuracy: 0.9167 - val_loss: 0.2185 - val_accuracy: 0.9268\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 902us/step - loss: 0.2076 - accuracy: 0.9146 - val_loss: 0.2180 - val_accuracy: 0.9268\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 751us/step - loss: 0.2067 - accuracy: 0.9146 - val_loss: 0.2170 - val_accuracy: 0.9350\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 738us/step - loss: 0.2050 - accuracy: 0.9207 - val_loss: 0.2173 - val_accuracy: 0.9350\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 753us/step - loss: 0.2037 - accuracy: 0.9248 - val_loss: 0.2168 - val_accuracy: 0.9350\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.2026 - accuracy: 0.9268 - val_loss: 0.2163 - val_accuracy: 0.9431\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 702us/step - loss: 0.2014 - accuracy: 0.9268 - val_loss: 0.2154 - val_accuracy: 0.9431\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 705us/step - loss: 0.2005 - accuracy: 0.9268 - val_loss: 0.2151 - val_accuracy: 0.9431\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 733us/step - loss: 0.1997 - accuracy: 0.9268 - val_loss: 0.2146 - val_accuracy: 0.9431\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 742us/step - loss: 0.1985 - accuracy: 0.9268 - val_loss: 0.2141 - val_accuracy: 0.9431\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 726us/step - loss: 0.1978 - accuracy: 0.9268 - val_loss: 0.2135 - val_accuracy: 0.9431\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 724us/step - loss: 0.1972 - accuracy: 0.9268 - val_loss: 0.2133 - val_accuracy: 0.9431\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 740us/step - loss: 0.1963 - accuracy: 0.9268 - val_loss: 0.2129 - val_accuracy: 0.9431\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 714us/step - loss: 0.1955 - accuracy: 0.9268 - val_loss: 0.2131 - val_accuracy: 0.9512\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 708us/step - loss: 0.1949 - accuracy: 0.9228 - val_loss: 0.2126 - val_accuracy: 0.9512\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 757us/step - loss: 0.1945 - accuracy: 0.9268 - val_loss: 0.2125 - val_accuracy: 0.9512\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 754us/step - loss: 0.1940 - accuracy: 0.9268 - val_loss: 0.2118 - val_accuracy: 0.9512\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 757us/step - loss: 0.1935 - accuracy: 0.9248 - val_loss: 0.2115 - val_accuracy: 0.9512\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 763us/step - loss: 0.1932 - accuracy: 0.9268 - val_loss: 0.2116 - val_accuracy: 0.9512\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 779us/step - loss: 0.1929 - accuracy: 0.9268 - val_loss: 0.2112 - val_accuracy: 0.9512\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 745us/step - loss: 0.1922 - accuracy: 0.9268 - val_loss: 0.2110 - val_accuracy: 0.9512\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 767us/step - loss: 0.1920 - accuracy: 0.9248 - val_loss: 0.2108 - val_accuracy: 0.9512\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 784us/step - loss: 0.1916 - accuracy: 0.9268 - val_loss: 0.2102 - val_accuracy: 0.9512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 760us/step - loss: 0.1915 - accuracy: 0.9248 - val_loss: 0.2101 - val_accuracy: 0.9512\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 724us/step - loss: 0.1911 - accuracy: 0.9268 - val_loss: 0.2099 - val_accuracy: 0.9512\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 748us/step - loss: 0.1908 - accuracy: 0.9268 - val_loss: 0.2096 - val_accuracy: 0.9512\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 740us/step - loss: 0.1904 - accuracy: 0.9268 - val_loss: 0.2094 - val_accuracy: 0.9512\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 813us/step - loss: 0.1900 - accuracy: 0.9248 - val_loss: 0.2088 - val_accuracy: 0.9512\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 788us/step - loss: 0.1894 - accuracy: 0.9268 - val_loss: 0.2087 - val_accuracy: 0.9512\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.1889 - accuracy: 0.9268 - val_loss: 0.2083 - val_accuracy: 0.9512\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 740us/step - loss: 0.1885 - accuracy: 0.9268 - val_loss: 0.2077 - val_accuracy: 0.9512\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 760us/step - loss: 0.1881 - accuracy: 0.9268 - val_loss: 0.2077 - val_accuracy: 0.9512\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 761us/step - loss: 0.1876 - accuracy: 0.9268 - val_loss: 0.2075 - val_accuracy: 0.9512\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 772us/step - loss: 0.1872 - accuracy: 0.9268 - val_loss: 0.2072 - val_accuracy: 0.9512\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 724us/step - loss: 0.1870 - accuracy: 0.9268 - val_loss: 0.2072 - val_accuracy: 0.9512\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 772us/step - loss: 0.1866 - accuracy: 0.9268 - val_loss: 0.2065 - val_accuracy: 0.9512\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 778us/step - loss: 0.1860 - accuracy: 0.9248 - val_loss: 0.2060 - val_accuracy: 0.9512\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 777us/step - loss: 0.1855 - accuracy: 0.9268 - val_loss: 0.2062 - val_accuracy: 0.9512\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 705us/step - loss: 0.1850 - accuracy: 0.9268 - val_loss: 0.2063 - val_accuracy: 0.9512\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 798us/step - loss: 0.1846 - accuracy: 0.9268 - val_loss: 0.2055 - val_accuracy: 0.9512\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 754us/step - loss: 0.1845 - accuracy: 0.9248 - val_loss: 0.2056 - val_accuracy: 0.9512\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 744us/step - loss: 0.1839 - accuracy: 0.9268 - val_loss: 0.2056 - val_accuracy: 0.9512\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 766us/step - loss: 0.1832 - accuracy: 0.9289 - val_loss: 0.2056 - val_accuracy: 0.9512\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 801us/step - loss: 0.1831 - accuracy: 0.9228 - val_loss: 0.2048 - val_accuracy: 0.9512\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 771us/step - loss: 0.1827 - accuracy: 0.9248 - val_loss: 0.2051 - val_accuracy: 0.9512\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 726us/step - loss: 0.1823 - accuracy: 0.9268 - val_loss: 0.2048 - val_accuracy: 0.9512\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 756us/step - loss: 0.1817 - accuracy: 0.9268 - val_loss: 0.2049 - val_accuracy: 0.9512\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 754us/step - loss: 0.1815 - accuracy: 0.9248 - val_loss: 0.2045 - val_accuracy: 0.9512\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 743us/step - loss: 0.1811 - accuracy: 0.9228 - val_loss: 0.2044 - val_accuracy: 0.9512\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 742us/step - loss: 0.1806 - accuracy: 0.9268 - val_loss: 0.2045 - val_accuracy: 0.9512\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 764us/step - loss: 0.1806 - accuracy: 0.9248 - val_loss: 0.2036 - val_accuracy: 0.9512\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 770us/step - loss: 0.1798 - accuracy: 0.9268 - val_loss: 0.2040 - val_accuracy: 0.9512\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 788us/step - loss: 0.1795 - accuracy: 0.9289 - val_loss: 0.2042 - val_accuracy: 0.9512\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 752us/step - loss: 0.1792 - accuracy: 0.9268 - val_loss: 0.2038 - val_accuracy: 0.9512\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 765us/step - loss: 0.1792 - accuracy: 0.9289 - val_loss: 0.2043 - val_accuracy: 0.9512\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 756us/step - loss: 0.1786 - accuracy: 0.9289 - val_loss: 0.2034 - val_accuracy: 0.9512\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 740us/step - loss: 0.1784 - accuracy: 0.9289 - val_loss: 0.2033 - val_accuracy: 0.9512\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 747us/step - loss: 0.1780 - accuracy: 0.9268 - val_loss: 0.2033 - val_accuracy: 0.9512\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 740us/step - loss: 0.1777 - accuracy: 0.9289 - val_loss: 0.2035 - val_accuracy: 0.9512\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 802us/step - loss: 0.1776 - accuracy: 0.9289 - val_loss: 0.2028 - val_accuracy: 0.9512\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 724us/step - loss: 0.1772 - accuracy: 0.9289 - val_loss: 0.2036 - val_accuracy: 0.9512\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 724us/step - loss: 0.1770 - accuracy: 0.9248 - val_loss: 0.2026 - val_accuracy: 0.9512\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 733us/step - loss: 0.1767 - accuracy: 0.9248 - val_loss: 0.2040 - val_accuracy: 0.9512\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 721us/step - loss: 0.1765 - accuracy: 0.9268 - val_loss: 0.2035 - val_accuracy: 0.9512\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 743us/step - loss: 0.1762 - accuracy: 0.9268 - val_loss: 0.2035 - val_accuracy: 0.9512\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 740us/step - loss: 0.1759 - accuracy: 0.9248 - val_loss: 0.2030 - val_accuracy: 0.9512\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "history = cnn.fit(X_train, y_train, batch_size = 8, epochs = 100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting loss & accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = cnn.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем прогнозирование, порог оставим прежний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106   2]\n",
      " [  4  11]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построив таблицу сопряженности, видим, что она стала лучше (было 6 неверно распознанных объектов, стало 4). При этом я увеличила количество нейронов на 1ом слое до 3, усложнять архитектуру на такой маленькой выборке смысла нет. 117 объектов распознаны верно,  модель обучилась и стала лучше."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
